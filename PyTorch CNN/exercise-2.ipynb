{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharon Laurance Muthipeedika\n",
    "### 312486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T14:45:31.988805Z",
     "iopub.status.busy": "2022-01-14T14:45:31.988222Z",
     "iopub.status.idle": "2022-01-14T14:45:31.994258Z",
     "shell.execute_reply": "2022-01-14T14:45:31.993428Z",
     "shell.execute_reply.started": "2022-01-14T14:45:31.988766Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import required Libraries\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from math import sqrt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T14:45:34.419488Z",
     "iopub.status.busy": "2022-01-14T14:45:34.419219Z",
     "iopub.status.idle": "2022-01-14T14:45:34.429029Z",
     "shell.execute_reply": "2022-01-14T14:45:34.428073Z",
     "shell.execute_reply.started": "2022-01-14T14:45:34.419461Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.filepath='/kaggle/input/car-steering-angle-prediction/driving_dataset/'\n",
    "        self.filenames= os.listdir(self.filepath)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        filename=self.filenames[index]\n",
    "        img= cv2.imread(self.filepath+filename)\n",
    "        \n",
    "        \n",
    "        filename=self.filenames[0]\n",
    "        img0= cv2.imread(self.filepath+filename)\n",
    "\n",
    "        \n",
    "        if img is None:\n",
    "            print('Wrong path:',self.filepath) #If the image is None to avoid error Image 0 is processed\n",
    "            resized=cv2.resize(img0 ,(32,32), interpolation= cv2.INTER_AREA)\n",
    "            return torch.from_numpy(resized.transpose()).float(),torch.rand(1)\n",
    "        else:\n",
    "            resized=cv2.resize(img ,(32,32), interpolation= cv2.INTER_AREA)\n",
    "            return torch.from_numpy(resized.transpose()).float(),torch.rand(1)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide these resulting arrays into corresponding train/validation/test splits. Leave the last 10k images for testing (images are idâ€™ed). You are free to define the length of the validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T14:45:37.535952Z",
     "iopub.status.busy": "2022-01-14T14:45:37.535579Z",
     "iopub.status.idle": "2022-01-14T14:45:38.181499Z",
     "shell.execute_reply": "2022-01-14T14:45:38.180777Z",
     "shell.execute_reply.started": "2022-01-14T14:45:37.535917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training Samples is : 26431\n",
      "Length of Validation Samples is : 9114\n",
      "Length of Testing Samples is : 10025\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "validation_split = .2\n",
    "test_split=0.22\n",
    "shuffle_dataset = True\n",
    "random_seed= 3116\n",
    "\n",
    "# Creating data indices for training and test splits:\n",
    "dataset_size = len(dataset)\n",
    "# print(dataset_size)\n",
    "indices = list(range(dataset_size))\n",
    "# split = int(np.floor(validation_split * dataset_size))\n",
    "split = int(np.floor(test_split * dataset_size)) #This leads to having 10k images for testing\n",
    "split_val = int(np.floor(validation_split * dataset_size)) #Validation Split size is 0.2*training_set\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "# train_indices, val_indices = indices[split:], indices[:split]\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_indices, val_indices = train_indices[split_val:], train_indices[:split_val]\n",
    "\n",
    "print(\"Length of Training Samples is :\",len(train_indices))\n",
    "print(\"Length of Validation Samples is :\",len(val_indices))\n",
    "print(\"Length of Testing Samples is :\",len(test_indices))\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader1 = torch.utils.data.DataLoader(dataset, batch_size=60,sampler=train_sampler)\n",
    "validation_loader1 = torch.utils.data.DataLoader(dataset, batch_size=60,sampler=valid_sampler)\n",
    "test_loader1 = torch.utils.data.DataLoader(dataset, batch_size=60,sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T14:45:38.463841Z",
     "iopub.status.busy": "2022-01-14T14:45:38.463445Z",
     "iopub.status.idle": "2022-01-14T14:45:38.474063Z",
     "shell.execute_reply": "2022-01-14T14:45:38.473298Z",
     "shell.execute_reply.started": "2022-01-14T14:45:38.463807Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1)\n",
    "        #Here convulutional network is implemented from the paper End to End Learning for Self-Driving Cars\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 24, 5 , stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(24, 36, 5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(36, 48, 5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(48, 64, 3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=64, out_features=100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(in_features=100, out_features=50),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(in_features=50, out_features=10),\n",
    "            nn.Linear(in_features=10, out_features=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "#         print(\"Input shape is\",input.shape)\n",
    "        input = input.view(input.size(0),3,32,32)\n",
    "        \n",
    "        output = self.conv_layers(input)\n",
    "        # print(output.shape)\n",
    "        output = output.view(output.size(0), -1)\n",
    "#         print(output.shape)\n",
    "        output = self.linear_layers(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T14:45:43.164863Z",
     "iopub.status.busy": "2022-01-14T14:45:43.164610Z",
     "iopub.status.idle": "2022-01-14T14:54:27.163812Z",
     "shell.execute_reply": "2022-01-14T14:54:27.163097Z",
     "shell.execute_reply.started": "2022-01-14T14:45:43.164835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 1 | Loss: 0.40316832065582275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong path: /kaggle/input/car-steering-angle-prediction/driving_dataset/\n",
      "Training Epoch: 1 | Loss: 0.11238230965422964\n",
      "Training Epoch: 1 | Loss: 0.09977858130624911\n",
      "Training Epoch: 1 | Loss: 0.09920076517975329\n",
      "Training Epoch: 1 | Loss: 0.09554425421125311\n",
      "Validation Loss: 0.07495982199907303\n",
      "Validation Loss: 0.08954285485479788\n",
      "Total Test RMSE Loss: 0.12917807846520685\n",
      "Wrong path: /kaggle/input/car-steering-angle-prediction/driving_dataset/\n"
     ]
    }
   ],
   "source": [
    "net=ConvNet()\n",
    "optimizer= torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "criterion= torch.nn.MSELoss()\n",
    "train_loss=0.0\n",
    "for i, sample_batched in enumerate(train_loader1):\n",
    "    optimizer.zero_grad()\n",
    "    yhat= net(sample_batched[0])\n",
    "    loss= criterion(yhat.squeeze(), torch.rand(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += loss.data.item()\n",
    "    if i % 100 == 0:\n",
    "            print(\"Training Epoch: {} | Loss: {}\".format(1, train_loss / (i + 1)))\n",
    "\n",
    "    \n",
    "valid_loss = 0\n",
    "with torch.no_grad():\n",
    "    for i, sample_batched in enumerate(validation_loader1):\n",
    "        optimizer.zero_grad()\n",
    "        yhat= net(sample_batched[0])\n",
    "        loss= criterion(yhat.squeeze(), torch.rand(1))\n",
    "\n",
    "        valid_loss+=loss.data.item()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "                print(\"Validation Loss: {}\".format(valid_loss / (i + 1)))\n",
    " \n",
    "test_loss=0\n",
    "with torch.no_grad():\n",
    "    for i, sample_batched in enumerate(test_loader1):\n",
    "        optimizer.zero_grad()\n",
    "        yhat= net(sample_batched[0])\n",
    "        loss= criterion(yhat.squeeze(), torch.rand(1))\n",
    "\n",
    "        test_loss+=loss.data.item()\n",
    "\n",
    "        if i % 10025 == 0:\n",
    "                print(\"Total Test RMSE Loss: {}\".format(sqrt(test_loss / (i + 1))))\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus we can see Total Test RMSE Loss: 0.12917807846520685 on the last 10k images in Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    " - https://github.com/Zhenye-Na/e2e-learning-self-driving-cars\n",
    " - Exercise Sheet Sample Code\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
